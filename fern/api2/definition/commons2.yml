# yaml-language-server: $schema=https://raw.githubusercontent.com/fern-api/fern/main/fern.schema.json

types:



  FieldRequest:
    properties:
      name: string
      data_type: DataTypes
      display_name: optional<string>
      required: optional<boolean>
      distinct_values: optional<list<string>>

  ProjectResponse:
    properties:
      id: integer
      name: string
      shared_id: optional<string>
      external_id: optional<string>
      active: boolean
      auth_key: string
      pred_count: integer
      created_at: string
      default_dataset_id: optional<integer>
      description: optional<string>
      guidelines: optional<string>
      instructions: optional<string>
      status: optional<ProjectStatus>
      updated_at: optional<string>
      inputs: list<ProjectInputResponse>
      outputs: list<ProjectOutputResponse>
      users: list<ProjectUserResponse>
      learner: optional<ProjectLearnerResponse>
      datasets: optional<list<ProjectDatasetResponse>>
      data_count: integer
      data_without_tasks_count: integer
      tasks_count: integer
      latest_completed_tasks_batch_size: integer
      completed_tasks_count: integer
      incomplete_tasks_count: integer
      flagged_count: integer
      task_allocation_strategy: TaskAllocationStrategy
      task_allocation_batch_size: integer

  OutputRequest:
    properties:
      name: string
      data_sources: optional<list<DataSource>>
      display_name: optional<string>
      description: optional<string>
      instructions: optional<string>
      data_type: optional<DataTypes>
      task_type: optional<TaskTypes>
      labels: optional<list<UpdateLabelRequest>>
      input: optional<string>

  DataSource:
    properties:
      field_id: integer

  TaskTypes:
    docs: What ML tasks we support for our outputs
    enum:
      - classification
      - multi_label_classification
      - sequence_tagging
      - ordinal_regression
      - generation

  UpdateLabelRequest:
    docs: >-
      The definition of a Label used as part of an output
      specification for a project and/or learner. The name will be a unique key
      (within the scope of a single output) that will be referenced by
      annotations
      and predictions
    properties:
      id: optional<string>
      name: optional<string>
      display_name: optional<string>
      description: optional<string>

  InputRequest:
    properties:
      name: string
      data_sources: optional<list<DataSource>>
      data_type: optional<DataTypes>
      description: optional<string>
      display_only: optional<boolean>

  Policy:
    docs: >-
      A policy for how how many annotations to get on some proportion of the
      data.
      Providing multiple annotations for the same data-points provides consensus
      metrics
      and can help improve the quality of the final annotations provided to the
      model
    properties:
      num_annotators: optional<integer>
      data_proportion: optional<double>
      object: optional<string>
      id: optional<string>

  TaskAllocationStrategy:
    docs: |-
      Strategy for automatic task allocation
      Controls whether new tasks are automatically allocated when a user
      completes their tasks.
    enum:
      - automatic
      - manual

  ProjectStatus:
    docs: Current status of learner
    enum:
      - Maintenance
      - Exploration
      - Annotation

  ProjectInputResponse:
    properties:
      data_type: DataTypes
      description: optional<string>
      data_sources: list<ProjectInputDataSourceResponse>
      display_only: boolean
      id: integer
      name: string
      project_id: integer
      updated_at: string
      created_at: string

  ProjectInputDataSourceResponse:
    properties:
      id: integer
      name: string

  ProjectOutputResponse:
    properties:
      created_at: string
      updated_at: optional<string>
      data_type: optional<DataTypes>
      description: optional<string>
      data_sources: list<ProjectInputDataSourceResponse>
      display_name: string
      id: integer
      input: optional<string>
      instructions: optional<string>
      labels: optional<list<LabelResponse>>
      name: string
      project_id: integer
      task_type: TaskTypes

  LabelResponse:
    docs: Data returned in the payload when adding, editing or deleting a label(s)
    properties:
      name: string
      id: string
      display_name: optional<string>
      description: optional<string>
      count: optional<integer>
      object: optional<string>
      output_id: integer
      output: optional<OutputResponse>
      created_at: optional<string>
      updated_at: optional<string>

  OutputResponse:
    docs: Output data to be nested inside the label response payload
    properties:
      id: optional<integer>
      name: string
      display_name: optional<string>
      description: optional<string>
      task_type: TaskTypes
      data_key: optional<string>
      data_type: optional<DataTypes>
      project_id: optional<integer>
      object: optional<string>

  ProjectUserResponse:
    properties:
      active: boolean
      email_address: string
      full_name: optional<string>
      id: integer
      role: RoleEnum
      tier_id: integer
      tier: ProjectUserTierResponse
      created_at: string
      updated_at: optional<string>
      username: string
      verified: boolean
      complete_tasks: optional<integer>
      incomplete_tasks: optional<integer>
      complete_and_not_flagged_tasks: optional<integer>
      incomplete_and_not_flagged_tasks: optional<integer>

  ProjectUserTierResponse:
    properties:
      updated_at: string
      created_at: string
      id: integer
      name: string
      limits: ProjectUserTierLimitsResponse

  ProjectUserTierLimitsResponse:
    properties:
      projects: integer
      annotators: integer
      dataset_size: integer
      predictions: integer

  ProjectLearnerResponse:
    properties:
      id: integer
      current_status: Status
      evaluations: optional<list<ProjectLearnerEvaluationResponse>>
      latest_evaluation: optional<ProjectLearnerEvaluationResponse>

  Status:
    docs: Current status of learner
    enum:
      - Untrained
      - Waiting
      - Training
      - Scoring

  ProjectLearnerEvaluationResponse:
    properties:
      id: integer
      created_at: optional<string>
      updated_at: optional<string>

  ProjectDatasetResponse:
    properties:
      id: integer
      name: string
      count: integer
      description: optional<string>
      fields: optional<list<ProjectDatasetFieldResponse>>

  ProjectDatasetFieldResponse:
    properties:
      id: integer
      name: string
      data_type: DataTypes
      display_name: optional<string>

  ProjectUpdateRequest:
    properties:
      name: optional<string>
      instructions: optional<string>
      guidelines: optional<string>
      description: optional<string>
      policy: optional<Policy>
      task_allocation_strategy: optional<TaskAllocationStrategy>
      task_allocation_batch_size: optional<integer>

  PredictResponse:
    properties:
      id: optional<integer>
      results: list<ResultResponse>
      usage: optional<ProjectDataUsage>

  ResultResponse:
    docs: An instance of a result
    properties:
      id: string
      confidence: optional<double>
      start: optional<integer>
      end: optional<integer>
      text: optional<string>
      label: LabelResponse
      result_type: ResultType

  ResultType:
    docs: Enum of different kinds of result
    enum:
      - span
      - classification
      - generation

  ProjectDataUsage:
    docs: How a data point has been used when updating an AI model for this project
    enum:
      - testing
      - validation
      - training

  PredictWithFallbackResponse:
    properties:
      prediction_id: optional<integer>
      batch_id: optional<string>
      data_id: integer
      results: optional<list<ResultResponse>>
      confidence_threshold: optional<double>
      created_at: optional<string>
      task_id: optional<integer>
      user: optional<string>
      task_url: optional<string>

  EvaluationResponse:
    properties:
      id: integer
      learner_id: integer
      eval_metrics: EvalMetrics
      created_at: string
      updated_at: optional<string>

  EvalMetrics:
    properties:
      train_loss: list<double>
      dev_loss: list<double>
      test_loss: list<double>
      train_eval: list<EvalItem>
      dev_eval: list<EvalItem>
      test_eval: list<EvalItem>
      learning_rate: list<double>
      test_score: optional<double>
      num_labels: integer

  EvalItem:
    properties:
      main_score: double
      accuracy: double
      macro_f_score: double
      micro_f_score: double
      class_breakdown: map<string, ClassBreakdown>

  ClassBreakdown:
    properties:
      precision: double
      recall: double
      f1-score: double
      support: integer

  TaskResponse:
    properties:
      id: integer
      user_id: integer
      full_name: optional<string>
      email_address: string
      project_id: integer
      project_data_id: integer
      data_id: integer
      complete: optional<boolean>
      flagged: optional<boolean>
      score: optional<double>
      usage: optional<ProjectDataUsage>
      url: optional<string>
      comment: optional<string>
      annotations: list<TaskAnnotationResponse>
      predictions: list<TaskPredictionResponse>
      created_at: optional<string>
      updated_at: optional<string>

  TaskAnnotationResponse:
    docs: >-
      This response model comes from the annotations retrieved by
      get_tasks_dataframe().
      Kept separate from AnnotationResponse to avoid nested attributes
      (like full Label, annotation's task information etc.).
    properties:
      id: string
      result_type: ResultType
      start: optional<integer>
      end: optional<integer>
      text: optional<string>
      label_id: string
      label_name: string
      label_display_name: optional<string>
      label_description: optional<string>

  TaskPredictionResponse:
    docs: >-
      Backend currently only returns active learning predictions (not
      user-generated predictions).
      This response model comes from the predictions retrieved by
      get_tasks_dataframe(),
      and is actually on a Result-level
      (i.e. one object = one prediction result. A single prediction with
      multiple results will yield multiple objects.)
    properties:
      id: string
      result_id: string
      result_type: ResultType
      start: optional<integer>
      end: optional<integer>
      text: optional<string>
      confidence: optional<double>
      label_id: string
      label_name: string
      label_display_name: optional<string>
      label_description: optional<string>
      created_at: string
      updated_at: string

  SubRequest:
    properties:
      event: optional<Event>
      callback_url: optional<string>
      email_address: optional<string>
      active: optional<boolean>

  Event:
    docs: "Events users of Humanloop can subscribe to "
    enum:
      - task.completed
      - task.created

  LogResponse:
    properties:
      id: string
      source: optional<string>
      model_config: >-
        optional<ProjectModelConfigResponse>
      output: string
      feedback: optional<list<FeedbackResponse>>
      metric_values: optional<list<MetricValueResponse>>
      data_snapshots: optional<list<LogDataSnapshot>>
      provider_latency: optional<double>
      created_at: string
      updated_at: string

  ProjectModelConfigResponse:
    docs: >-
      Extends the core ModelConfig request object to include Humanloop generated
      identifier and method for serializing response from ModelConfig domain
      object.
    properties:
      provider:
        docs: The company providing the underlying model service.
        type: ModelProviders
      endpoint:
        docs: >-
          Which of the providers model endpoints to use. For example Complete or
          Edit.
        type: ModelEndpoints
      model: string
      prompt_template: string
      temperature: optional<double>
      max_tokens: optional<integer>
      top_p: optional<double>
      presence_penalty: optional<double>
      frequency_penalty: optional<double>
      id: string
      display_name: optional<string>
      project_id: optional<string>
      created_at: string
      updated_at: string
      last_used: string
      feedback_stats: optional<list<ProjectModelConfigFeedbackStatsResponse>>
      experiment_id: optional<string>

  ModelProviders:
    docs: Supported model providers.
    enum:
      - openai
      - ai21
      - mock
      - anthropic

  ModelEndpoints:
    docs: Supported model provider endpoints.
    enum:
      - complete
      - edit

  ProjectModelConfigFeedbackStatsResponse:
    properties:
      feedback_group_id: integer
      feedback_group_name: string
      feedback_label: string
      feedback_count: integer

  FeedbackResponse:
    properties:
      value: string
      data_id: optional<string>
      user: optional<string>
      created_at: optional<string>
      id: string

  MetricValueResponse:
    properties:
      metric_id: string
      metric_name: string
      metric_value: double

  LogDataSnapshot:
    properties:
      id: string
      name: string
      count: integer

  ProjectModelConfigResponse:
    properties:
      id: string
      project_id: optional<string>
      display_name: string
      model_name: string
      prompt_template: optional<string>
      provider:
        docs: The organization hosting the target model.
        type: optional<ModelProviders>
      endpoint:
        docs: Which of the providers' endpoints to use. E.g. Complete, Edit.
        type: optional<ModelEndpoints>
      created_at: string
      updated_at: string
      last_used: string
      experiment_id: optional<string>

  FineTunedModelResponse:
    properties:
      id: string
      name: string
      status: string
      model_name: optional<string>
      data_snapshot:
        docs: Details of the corresponding immutable dataset used for fine-tuning.
        type: DataSnapshotResponse
      provider_id: optional<string>
      config:
        docs: Configuration details for the fine-tuned model.
        type: FineTuneConfig
      created_at: string
      updated_at: string

  FineTuneConfig:
    properties:
      provider:
        docs: >-
          The company who is hosting the target model.This is used only if an
          existing experiment_id or model_config_id are not provided.
        type: optional<ModelProviders>
      base_model: string
      validation_split: optional<double>
      use_corrections: optional<boolean>
      prompt_template: optional<string>
      generation_template: optional<string>

  ProviderApiKeys:
    properties:
      openai: optional<string>
      ai21: optional<string>
      mock: optional<string>
      anthropic: optional<string>

  DataSnapshotResponse:
    properties:
      id: string
      name: string
      description: optional<string>
      count: integer
      created_at: string
      updated_at: string

  UpdateFineTunedModelsModel:
    properties:
      id: string
      error: optional<string>
